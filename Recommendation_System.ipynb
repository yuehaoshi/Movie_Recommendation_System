{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation System.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNemvzprmIWeiq1mvsfP35D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuehaoshi/Movie_Recommendation_System/blob/main/Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aggregation"
      ],
      "metadata": {
        "id": "Hn_GwSDDzR6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5fvA2B5zNkb"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(data_ori):\n",
        "    # Split Movies and TV Shows\n",
        "    data_movie = data_ori[data_ori['type'] == 'Movie']\n",
        "    data_tv = data_ori[data_ori['type'] == 'TV Show']\n",
        "    data_movie.drop(columns='type',axis=1,inplace=True)\n",
        "    data_tv.drop(columns='type',axis=1,inplace=True)\n",
        "    # Country\n",
        "    data_movie = prepare_country(data_movie)\n",
        "    data_tv = prepare_country(data_tv)\n",
        "    # Director, Country, Cast\n",
        "    data_movie = one_hot(data_movie, 'director')\n",
        "    data_movie = one_hot(data_movie, 'country')\n",
        "    data_movie = one_hot(data_movie, 'cast')\n",
        "    data_tv = one_hot(data_tv, 'cast') \n",
        "    data_tv = one_hot(data_tv, 'country')\n",
        "    # Rating\n",
        "    data_movie = prepare_rating(data_movie)\n",
        "    data_tv = prepare_rating(data_tv)\n",
        "    # Duration\n",
        "    data_tv = prepare_duration(data_tv,False)\n",
        "    data_movie = prepare_duration(data_movie,True)\n",
        "    # Genre\n",
        "    data_movie, movie_g = prepare_genre(data_movie)\n",
        "    data_tv, tv_g = prepare_genre(data_tv)\n",
        "    # Release_year, Date_added\n",
        "    data_movie = prepare_release_add(data_movie)\n",
        "    data_tv = prepare_release_add(data_tv)\n",
        "\n",
        "    return data_movie, data_tv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_movie, data_tv = prepare_dataset(data_ori)"
      ],
      "metadata": {
        "id": "fibEfXtkzaJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(vec1,vec2):\n",
        "    return np.linalg.norm(vec1-vec2)\n",
        "    # return vec1.dot(vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
        "\n",
        "def recommend(name,data_movie,data_tv,data_ori, rec_num=5):\n",
        "    is_movie = data_movie[\"title\"].isin([name])\n",
        "    is_tv = data_tv[\"title\"].isin([name])\n",
        "    result = pd.DataFrame()    \n",
        "    if is_movie.any():\n",
        "        movie_show_id = movie_rec(data_movie, is_movie, rec_num+1)\n",
        "        for show_id in movie_show_id:\n",
        "            result = pd.concat((result,data_ori[data_ori['show_id']==show_id]),axis=0)\n",
        "    elif is_tv.any():\n",
        "        tv_show_id = tv_rec(data_tv, is_tv, rec_num+1)\n",
        "        for show_id in tv_show_id:\n",
        "            result = pd.concat((result,data_ori[data_ori['show_id']==show_id]),axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"Entry is not found in the library.\")    \n",
        "    return result\n",
        "\n",
        "from queue import PriorityQueue\n",
        "def movie_rec(data_movie, condition,rec_num):\n",
        "    data_movie_copy = data_movie.drop(columns=['show_id','description','title'],axis=1)\n",
        "    input_row = data_movie_copy[condition].squeeze()\n",
        "    dist_list = PriorityQueue()\n",
        "    for i in range(data_movie_copy.shape[0]):\n",
        "        dist_list.put((dist(input_row,data_movie_copy.iloc[i,:]),i))\n",
        "    result = []\n",
        "    for j in range(rec_num):\n",
        "        result.append(dist_list.get()[1])\n",
        "    show_id_idx = list(data_movie.columns).index(\"show_id\")\n",
        "    return data_movie.iloc[result,show_id_idx]\n",
        "\n",
        "def tv_rec(data_tv, condition, rec_num):\n",
        "    data_tv_copy = data_tv.drop(columns=['director','show_id','description','title'],axis=1)\n",
        "    input_row = data_tv_copy[condition].squeeze()\n",
        "    dist_list = PriorityQueue()\n",
        "    for i in range(data_tv_copy.shape[0]):\n",
        "        dist_list.put((dist(input_row,data_tv_copy.iloc[i,:]),i))\n",
        "    result = []\n",
        "    for j in range(rec_num):\n",
        "        result.append(dist_list.get()[1])\n",
        "    show_id_idx = list(data_tv.columns).index(\"show_id\")\n",
        "    return data_tv.iloc[result,show_id_idx]"
      ],
      "metadata": {
        "id": "EN6KrWQ-ze4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Angamaly Diaries',data_movie,data_tv,data_ori)"
      ],
      "metadata": {
        "id": "-7hZg186zf2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Dive Club',data_movie,data_tv,data_ori)"
      ],
      "metadata": {
        "id": "wCbBELFqziYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding NLP"
      ],
      "metadata": {
        "id": "OdqxOxYazsvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake_nltk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from rake_nltk import Rake"
      ],
      "metadata": {
        "id": "Lgo1wyprzuhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "9JASxDY0zyAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data_ori):\n",
        "    # Split Movies and TV Shows\n",
        "    data_movie = data_ori[data_ori['type'] == 'Movie']\n",
        "    data_tv = data_ori[data_ori['type'] == 'TV Show']\n",
        "    data_movie.drop(columns='type',axis=1,inplace=True)\n",
        "    data_tv.drop(columns='type',axis=1,inplace=True)\n",
        "    # Country\n",
        "    data_movie = prepare_country(data_movie)\n",
        "    data_tv = prepare_country(data_tv)\n",
        "    # Director, Country, Cast\n",
        "    data_movie = one_hot(data_movie, 'director')\n",
        "    data_movie = one_hot(data_movie, 'country')\n",
        "    data_movie = one_hot(data_movie, 'cast')\n",
        "    data_tv = one_hot(data_tv, 'cast') \n",
        "    data_tv = one_hot(data_tv, 'country')\n",
        "    # Rating\n",
        "    data_movie = prepare_rating(data_movie)\n",
        "    data_tv = prepare_rating(data_tv)\n",
        "    # Duration\n",
        "    data_tv = prepare_duration(data_tv,False)\n",
        "    data_movie = prepare_duration(data_movie,True)\n",
        "    # Genre\n",
        "    data_movie, movie_g = prepare_genre(data_movie)\n",
        "    data_tv, tv_g = prepare_genre(data_tv)\n",
        "    # Release_year, Date_added\n",
        "    data_movie = prepare_release_add(data_movie)\n",
        "    data_tv = prepare_release_add(data_tv)\n",
        "\n",
        "    return data_movie, data_tv"
      ],
      "metadata": {
        "id": "_dKFCdZtz0IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_movie, data_tv = prepare_dataset(data_ori)"
      ],
      "metadata": {
        "id": "77onfOEyz3rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/nishadjoshi98/visualization-analysis-and-recommendation-system\n",
        "rake = Rake()\n",
        "nlp_movie = data_movie[['title','description']]\n",
        "nlp_tv = data_tv[['title','description']]"
      ],
      "metadata": {
        "id": "RVuRlqknz58J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_movie['key_notes'] = ''\n",
        "nlp_tv['key_notes'] = ''\n",
        "for index,row in nlp_movie.iterrows():\n",
        "    plot = row['description']   \n",
        "    rake.extract_keywords_from_text(plot)\n",
        "    keyword_score = rake.get_word_degrees()\n",
        "    keyword_score = ' '.join(list(keyword_score.keys()))\n",
        "    row['key_notes'] = keyword_score\n",
        "for index,row in nlp_tv.iterrows():\n",
        "    plot = row['description']   \n",
        "    rake.extract_keywords_from_text(plot)\n",
        "    keyword_score = rake.get_word_degrees()\n",
        "    keyword_score = ' '.join(list(keyword_score.keys()))\n",
        "    row['key_notes'] = keyword_score\n",
        "recommend_movie = nlp_movie[['title','key_notes']]\n",
        "recommend_tv = nlp_tv[['title','key_notes']]\n",
        "#print(recommend_tv)\n",
        "\n",
        "cv_movie = CountVectorizer()\n",
        "count_mat_movie = cv_movie.fit_transform(recommend_movie['key_notes'])\n",
        "cosine_sim_movie = cosine_similarity(count_mat_movie,count_mat_movie)\n",
        "cv_tv = CountVectorizer()\n",
        "count_mat_tv = cv_tv.fit_transform(recommend_tv['key_notes'])\n",
        "cosine_sim_tv = cosine_similarity(count_mat_tv,count_mat_tv)\n",
        "#print(cosine_sim_tv)"
      ],
      "metadata": {
        "id": "bvGb8RZQz_LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(vec1,vec2):\n",
        "    return np.linalg.norm(vec1-vec2)\n",
        "    # return vec1.dot(vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
        "\n",
        "def recommend_new(name,data_movie,data_tv,data_ori, rec_num=5):\n",
        "    is_movie = data_movie[\"title\"].isin([name])\n",
        "    is_tv = data_tv[\"title\"].isin([name])\n",
        "    result = pd.DataFrame()    \n",
        "    if is_movie.any():\n",
        "        movie_show_id = movie_rec_new(data_movie, is_movie, rec_num+1)\n",
        "        for show_id in movie_show_id:\n",
        "            result = pd.concat((result,data_ori[data_ori['show_id']==show_id]),axis=0)\n",
        "    elif is_tv.any():\n",
        "        tv_show_id = tv_rec_new(data_tv, is_tv, rec_num+1)\n",
        "        for show_id in tv_show_id:\n",
        "            result = pd.concat((result,data_ori[data_ori['show_id']==show_id]),axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"Entry is not found in the library.\")    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(data_movie.shape[0])\n",
        "print(cosine_sim_movie.shape)\n",
        "\n",
        "from queue import PriorityQueue\n",
        "def movie_rec_new(data_movie, condition,rec_num):\n",
        "    #data_movie1 = data_movie.head(100)\n",
        "    data_movie_copy = data_movie.drop(columns=['show_id','description','title'],axis=1)\n",
        "    input_row = data_movie_copy[condition].squeeze()\n",
        "    #dist_list = PriorityQueue()\n",
        "    sim1 = []\n",
        "    sim2 = []\n",
        "    idx = np.where(condition == True)[0][0]\n",
        "    for i in range(data_movie_copy.shape[0]):\n",
        "        #dist1.append(dist(input_row,data_movie_copy.iloc[i,:]))\n",
        "        if i != idx:\n",
        "          #print(input_row)\n",
        "          #print(data_movie_copy.iloc[i])\n",
        "          sim1.append(np.dot(input_row,data_movie_copy.iloc[i])/(np.linalg.norm(input_row)*np.linalg.norm(data_movie_copy.iloc[i])))\n",
        "          sim2.append(cosine_sim_movie[idx][i])\n",
        "          #print(\"dist1\", dist1)\n",
        "          #print(\"dist2\", dist2)\n",
        "          #dist_list.put((dist1 + 50*dist2,i))\n",
        "    result = []\n",
        "    #norm1 = np.linalg.norm(dist1)\n",
        "    sims = []\n",
        "    for (x, y) in zip(sim1, sim2):\n",
        "      sims.append(x + y)\n",
        "    sorted = np.argsort(sims)\n",
        "    result = sorted[::-1][:rec_num]\n",
        "    print(\"sim1\", len(sim1))\n",
        "    print(\"dists\", sims)\n",
        "    print(\"result\", result)\n",
        "    #for j in range(rec_num):\n",
        "        #result.append(dist_list.get()[1])\n",
        "    show_id_idx = list(data_movie.columns).index(\"show_id\")\n",
        "    return data_movie.iloc[result,show_id_idx]\n",
        "\n",
        "def tv_rec_new(data_tv, condition, rec_num):\n",
        "    data_tv1 = data_tv.head(100)\n",
        "    data_tv_copy = data_tv1.drop(columns=['director','show_id','description','title'],axis=1)\n",
        "    input_row = data_tv_copy[condition].squeeze()\n",
        "    sim1 = []\n",
        "    sim2 = []\n",
        "    idx = np.where(condition == True)[0][0]\n",
        "    for i in range(data_tv_copy.shape[0]):\n",
        "        if i != idx:\n",
        "          print(input_row)\n",
        "          print(data_tv_copy.iloc[i])\n",
        "          sim1.append(np.dot(input_row,data_tv_copy.iloc[i])/(np.linalg.norm(input_row)*np.linalg.norm(data_tv_copy.iloc[i])))\n",
        "          sim2.append(cosine_sim_tv[idx][i])\n",
        "    result = []\n",
        "    sims = []\n",
        "    for (x, y) in zip(sim1, sim2):\n",
        "      sims.append(x + y)\n",
        "    sorted = np.argsort(sims)\n",
        "    result = sorted[::-1][:rec_num]\n",
        "    show_id_idx = list(data_tv.columns).index(\"show_id\")\n",
        "    return data_tv.iloc[result,show_id_idx]"
      ],
      "metadata": {
        "id": "Blxv45aY0IKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_new('Sankofa',data_movie,data_tv,data_ori)"
      ],
      "metadata": {
        "id": "tT1ttQzH0LPS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}